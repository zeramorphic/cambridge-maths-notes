\subsection{Euler--Lagrange equation with constraints}
Given a functional \( F[y] = \int_\alpha^\beta f(x,y,y') \dd{x} \), we would like to extremise \( F \) subject to \( G[y] = \int_\alpha^\beta g(x,y,y') \dd{x} = k \) for some constant \( k \).
We can use the method of Lagrange multipliers.
Instead of extremising \( F \), we will extremise
\[
	\Phi[y;\lambda] = F[y] - \lambda G[y]
\]
Thus, we replace \( f \) in the Euler--Lagrange equation with \( f - \lambda g \), giving
\[
	\dv{x}\qty(\pdv{y'}(f-\lambda g)) - \pdv{y}(f-\lambda g) = 0
\]

\subsection{Dido's isoparametric problem}
Given a fixed perimeter, we wish to find the simple and closed plane curve which maximises the enclosed area.
We can restrict ourselves to convex curves.
This is because any concave curve can be transformed into a convex curve with greater area and equal perimeter, by reflecting the non-convex region.
We will parametrise the curve in \( \mathbb R^2 \) by letting the minimal and maximal values of \( x \) be \( \alpha, \beta \).
Then, as we trace out the curve, \( x \) monotonically increases from \( \alpha \) to \( \beta \), and then monotonically decreases as we return from \( \beta \) to \( \alpha \).
This induces two functions \( y_1, y_2 \) on \( (\alpha, \beta) \) where \( y_2 > y_1 \).
The infinitesimal area is given by \( \dd{A} = (y_2 - y_1) \dd{x} \).
Thus, the area functional is given by
\[
	A[y] = \int_\alpha^\beta (y_2(x) - y_1(x))\dd{x} = \oint_C y(x) \dd{y}
\]
The constraint functional is
\[
	L[y] = \oint_C \dd{\ell} = \oint_C \sqrt{1 + (y')^2} \dd{x} = L
\]
where \( L \) is the fixed perimeter.
Using Lagrange multipliers, we can define
\[
	h = y - \lambda \sqrt{1 + (y')^2}
\]
Note that we do not need to consider a boundary term in the derivation of the Euler--Lagrange equation, since the curve has no boundary.
Using a first integral form of the Euler--Lagrange equation on \( h \), we have
\[
	k = h - y'\dv{h}{y'} = y - \lambda \sqrt{1 + (y')^2} + y' \lambda \frac{y'}{\sqrt{1 + (y')^2}} = y - \frac{\lambda}{\sqrt{1 + (y')^2}}
\]
for some constant \( k \).
Hence,
\[
	(y')^2 = \frac{\lambda^2}{(y - k)^2} - 1
\]
A solution here is the circle of radius \( \lambda \):
\[
	(x - x_0)^2 + (y - y_0)^2 = \lambda^2
\]
Here, \( L = 2 \pi \lambda \) so we can write the solution in terms of \( L \) instead, giving
\[
	(x - x_0)^2 + (y - y_0)^2 = \frac{L^2}{4\pi^2}
\]

\subsection{The Sturm--Liouville problem}
Let \( \rho(x), \sigma(x) \) be defined for \( x \in [\alpha, \beta] \), and let \( \rho(x) > 0 \) on this interval.
Consider the functional
\[
	F[y] = \int_\alpha^\beta \qty[ \rho (y')^2 + \sigma y^2 ]\dd{x}
\]
Let us extremise \( F \) subject to the constraint
\[
	G[y] = \int_\alpha^\beta y^2 \dd{x} = 1
\]
We have
\[
	\Phi[y;\lambda]  F[y] - \lambda (G[y] - 1)
\]
This induces the integrand
\[
	h = \rho (y')^2 + \sigma y^2 - \lambda (y^2 - \frac{1}{\beta - \alpha})
\]
We consider the derivatives for the Euler--Lagrange equation:
\[
	\pdv{h}{y'} = 2 \rho y';\quad \pdv{h}{y} = 2 \sigma y - 2 \lambda y
\]
Hence,
\[
	-\dv{x}\qty(\rho y') + \sigma y = \lambda y
\]
We can write this as \( \mathcal L(y) = \lambda y \), where the \( \mathcal L \) is known as the Sturm--Liouville operator.
This is essentially an eigenvalue problem, since \( \mathcal L \) is a linear operator.
For example, if \( \rho = 1 \), this eigenvalue problem is exactly the time-independent Schr\"odinger equation where \( \sigma \) is the quantum-mechanical potential.

Suppose \( \sigma > 0 \).
Then the functional \( F[y] \) is also greater than zero.
Then, the positive minimum of \( F \) (if it exists) is the lowest eigenvalue.
\begin{proof}
	Using the result from the Euler--Lagrange equation, we can multiply by \( y \) and integrate by parts giving
	\begin{align*}
		-y\dv{x}\qty(\rho y') + \sigma y^2                         & = \lambda y^2                            \\
		F[y] - \underbrace{[y y' \rho]_\alpha^\beta}_{\text{zero}} & = \lambda \underbrace{G[y]}_{\text{one}}
	\end{align*}
	Thus, the lowest eigenvalue is the minimum of \( F[y] / G[y] \).
\end{proof}

\subsection{Multiple dependent variables}
Suppose we have some vector
\[
	\vb y(x) = (y_1(x), y_2(x), \dots, y_n(x))
\]
Suppose we want to extremise the functional
\[
	F[\vb y] = \int_\alpha^\beta f(x, y_1, \dots, y_n, y'_1, \dots, y'_n) \dd{x}
\]
If there is some critical point \( \vb y \), we perturb by a small amount \( \varepsilon\bm \eta = \varepsilon(\eta_1(x), \dots, \eta_n(x)) \), where \( \bm\eta(\alpha) = \bm\eta(\beta) = \vb 0 \).
Following the derivation of the one-dimensional Euler--Lagrange equation, we can deduce that
\[
	F[\vb y + \varepsilon \bm \eta] - F[\vb y] = \int_\alpha^\beta \sum_{i=1}^n \eta_i \qty(\dv{x}\pdv{f}{y_i'} - \pdv{f}{y_i})\dd{x} + \text{boundary term} + O(\varepsilon^2)
\]
We can apply the fundamental lemma, choosing \( \eta_i \) in a useful way, we can show that a necessary condition for a critical point is
\[
	\dv{x}\pdv{f}{y_i'} - \pdv{f}{y_i} = 0
\]
for all \( i \).
This is a second-order \textit{system} of \( n \) ODEs that we can solve.
If \( f \) does not depend on one of the \( y_i \), then we have a first integral form for this particular equation.
In particular, if \( \pdv{f}{y_j} \equiv 0 \) then \( \pdv{f}{y_j'} = \text{constant} \).
If \( f \) does not depend on \( x \), then we have \( f - \sum_i y_i' \pdv{f}{y_i'} = \text{constant} \).

\subsection{Geodesics on surfaces}
Consider a surface \( \Sigma \) in \( \mathbb R^3 \), given by
\[
	\Sigma = \qty{ \vb x \colon g(\vb x) = 0 }
\]
Consider two points \( A, B \) on \( \Sigma \).
What are the geodesics (shortest paths on the surface) between the two points, if one exists at all?
Consider a parametrisation of such a path given by \( t \in [0, 1] \) where \( A = \vb x(0), B = \vb x(1) \).
We wish to extremise
\[
	\Phi[\vb x, \lambda] = \int_0^1 \qty{ \sqrt{\dot x^2 + \dot y^2 + \dot z^2} - \lambda(t) g(\vb x) } \dd{t}
\]
The Lagrange multiplier, a function of \( t \), since we want the entire curve (for all \( t \)) to lie on \( \Sigma \).
We substitute the integrand \( h \) in the Euler--Lagrange equation.
Considering the variation with respect to \( \lambda \), we have
\[
	\dv{t} \pdv{h}{\dot\lambda} - \pdv{h}{\lambda} = 0
\]
But \( h \) does not depend on \( \dot\lambda \), hence \( \pdv{h}{\lambda} = 0 \), giving \( g(\vb x) = 0 \) for all \( \vb x \).
Considering the variation with respect to \( x_i \), we have
\[
	\dv{t} \pdv{h}{\dot x_i} - \pdv{h}{x_i} = 0
\]
Hence
\[
	\dv{t}\qty(\frac{\dot x_i}{\sqrt{\dot x_1^2 + \dot x_2^2 + \dot x_3^2}}) + \lambda \pdv{g}{x_i} = 0
\]
We could alternatively solve the constraint \( g = 0 \), and parametrise the surface according to this solution.

\subsection{Multiple independent variables}
In the most general case, we may have multiple independent variables in a variational problem.
This converts the Euler--Lagrange equation into a partial differential equation.
Suppose \( \phi \colon \mathbb R^n \to \mathbb R^m \).
If \( n = 3 \), for example, we have
\[
	F[\phi] = \iiint_{\mathcal D} f(\underbrace{x, y, z}_{\mathclap{\text{independent}}}, \phi, \phi_x, \phi_y, \phi_z) \dd{x}\dd{y}\dd{z}
\]
where \( \mathcal D \subset \mathbb R^3 \), and \( \phi_{x_i} := \pdv*{\phi}{x_i} \).
Suppose there exists some extremum \( \phi \), and consider a small variation \( \phi \mapsto \phi(x,y,z) + \varepsilon \eta(x,y,z) \) where \( \eta = 0 \) on \( \partial \mathcal D \).
Evaluating the functional on this perturbed \( \phi \) gives
\[
	F[\phi + \varepsilon\eta] - F[\phi] = \varepsilon \iiint_{\mathcal D} \qty{ \eta \pdv{f}{\phi} + \eta_x \pdv{f}{\phi_x} + \eta_y \pdv{f}{\phi_y} + \eta_z \pdv{f}{\phi_z} } \dd{x}\dd{y}\dd{z} + O(\varepsilon^2)
\]
\[
	= \varepsilon \iiint_{\mathcal D} \qty{ \eta \pdv{f}{\phi} + \underbrace{\nabla\cdot(\eta\qty(\pdv{f}{\phi_x}, \pdv{f}{\phi_y}, \pdv{f}{\phi_z}))}_{\mathclap{\text{apply divergence theorem since \( \eta \) vanishes on \( \partial \mathcal D \)}}} - \eta \nabla\cdot(\pdv{f}{\phi_x}, \pdv{f}{\phi_y}, \pdv{f}{\phi_z}) } \dd{x}\dd{y}\dd{z} + O(\varepsilon^2)
\]
\[
	= \varepsilon \iiint_{\mathcal D} \eta \qty{ \pdv{f}{\phi} - \nabla\cdot(\pdv{f}{\phi_x}, \pdv{f}{\phi_y}, \pdv{f}{\phi_z}) } \dd{x}\dd{y}\dd{z} + O(\varepsilon^2)
\]
% Doesn't fit on page if we are in an align environment.
Now, we can apply the fundamental lemma to give the Euler--Lagrange equation for multiple independent variables.
\[
	\pdv{f}{\phi} - \nabla\cdot(\pdv{f}{\phi_x},\pdv{f}{\phi_y},\pdv{f}{\phi_z}) = 0
\]
Or, in suffix notation (with the summation convention),
\[
	\pdv{f}{\phi} - \partial_i \pdv{f}{(\partial_i \phi)} = 0
\]
This result applies for any \( n \).
Note that this is now a partial differential equation for \( \phi \), instead of an ordinary differential equation.

\subsection{Potential energy and the Laplace equation}
Consider the functional
\[
	F[\phi] = \iint_{\mathcal D \subset \mathbb R^2} \frac{1}{2} \qty[\phi_x^2 + \phi_y^2] \dd{x}\dd{y}
\]
Note that \( \pdv{f}{\phi} = 0 \) and \( \pdv{f}{\phi_x} = \phi_x; \pdv{f}{\phi_y} = \phi_y \).
The Euler--Lagrange equation becomes
\[
	\pdv{x}\phi_x + \pdv{y}\phi_y = 0 \implies \phi_{xx} + \phi_{yy} = 0
\]
This produces the Laplace equation.

\subsection{Minimal surfaces}
Consider minimising the area of a surface \( \Sigma \subset \mathbb R^3 \), where we want the surface to have two boundaries defined by fixed closed curves.
This is sometimes known as Plateau's problem.
We will let \( \Sigma = \qty{ \vb x = \mathbb R^3 \colon k(x, y, z) = 0 } \), and assume there exists a parametrisation of \( \Sigma \) given by \( z = \phi(x, y) \).
The line element is given by
\[
	\dd{s}^2 = \dd{x}^2 + \dd{y}^2 + \dd{z}^2
\]
We have \( \dd{z} = \phi_x \dd{x} + \phi_y \dd{y} \) hence
\[
	\dd{s}^2 = ( 1 + \phi_x^2 ) \dd{x}^2 + ( 1 + \phi_y^2 ) \dd{y}^2 + 2 \phi_x \phi_y \dd{x}\dd{y}
\]
This is a quadratic form in the differentials \( \dd{x}, \dd{y} \), known as the first fundamental form (also the Riemannian metric).
Alternatively,
\[
	\dd{s}^2 = g_{ij}\dd{x^i}\dd{x^j}
\]
where
\[
	g = \begin{pmatrix}
		1 + \phi_x^2  & \phi_x \phi_y \\
		\phi_x \phi_y & 1 + \phi_y^2
	\end{pmatrix}
\]
From this, we can compute the area element, which is defined as
\[
	\dd{A} = \sqrt{\det g} \dd{x}\dd{y}
\]
We will extremise the area functional
\[
	A[\phi] = \int_{\mathcal D} \sqrt{1 + \phi_x^2 + \phi_y^2}\dd{x}\dd{y}
\]
Let the integrand be \( h \), and apply the Euler--Lagrange equation.
\[
	\pdv{h}{\phi_x} = \frac{\phi_x}{\sqrt{1 + \phi_x^2 + \phi_y^2}};\quad \pdv{h}{\phi_y} = \frac{\phi_y}{\sqrt{1 + \phi_x^2 + \phi_y^2}}
\]
Hence
\[
	\partial_x \qty(\frac{\phi_x}{\sqrt{1 + \phi_x^2 + \phi_y^2}}) + \partial_y \qty(\frac{\phi_x}{\sqrt{1 + \phi_x^2 + \phi_y^2}}) = 0
\]
which can be expanded to give
\[
	(1 + \phi_y^2)\phi_{xx} + (1 + \phi_x^2)\phi_{yy} - 2 \phi_x \phi_y \phi_{xy} = 0
\]
This is known as the minimal surface equation.
We will solve a special case, where there is circular (cylindrical) symmetry, so \( z = \phi(r) \).
Since \( r = \sqrt{x^2 + y^2} \), we can find that
\[
	\phi_x = z' \frac{x}{r};\quad \phi_y = z' \frac{y}{r}
\]
and we can analogously compute \( \phi_{xx}, \phi_{yy}, \phi_{xy} \).
This gives
\[
	rz'' + z' + (z')^3 = 0
\]

We can integrate this by first setting \( z' = w \) and multiplying through by \( w \).
\[
	\frac{1}{2}r\dv{r} w^2 + w^2 + w^4 = 0
\]
Now let \( w^2 = u \) to make this a separable equation for \( u \).
Solving this, we can find that the solution surface is given by
\[
	r = r_0 \cosh \qty(\frac{z-z_0}{r_0})
\]
This is known as the \textit{catenoid}.
At the maximal and minimal values of \( z \), we have the circular boundaries with radii \( R \).
At \( z = z_0 \), the radius is minimal, and the circle here has radius \( r_0 \).
Supposing \( z_0 = 0 \) and that the maximal value of \( z \) is \( L \), we have
\[
	\frac{R}{L} = \frac{r_0}{L} \cosh \qty(\frac{L}{r_0})
\]
Let \( L = 1 \) without loss of generality.
This essentially chooses a scale for the coordinate system.
This gives
\[
	R = r_0 \cosh \frac{1}{r_0}
\]
Plotting \( R \) as a function of \( r_0 \), there exists a minimum point \( r_0 = \mu \approx 0.833 \) which gives \( R \approx 1.5 \).
So if \( R > 1.5 \), there exist two distinct minimal surfaces, one with \( r_0 > \mu \) and one with \( r_0 < \mu \).
The `tighter' minimal surface (with \( r_0 < \mu \)) is unstable, but the `looser' surface is stable (however this cannot be shown from our current understanding of variational principles).

\subsection{Higher derivatives}
Consider the functional
\[
	F[y] = \int_\alpha^\beta f(x,y,y',\dots,y^{(n)}) \dd{x}
\]
We can find an analogous Euler--Lagrange equation to extremise this functional.
Let \( \eta \) be a variation where \( \eta^{(k)} = 0 \) for \( k \in \qty{1, \dots, n-1} \) at the endpoints \( \alpha, \beta \).
Now,
\[
	F[y+\varepsilon \eta] - F[y] = \varepsilon\int_\alpha^\beta \qty(\pdv{f}{y} \eta + \pdv{f}{y'}\eta' + \dots + \pdv{f}{y^{(n)}}\eta^{(n)}) \dd{x} + O(\varepsilon^2)
\]
We can repeatedly integrate each term by parts, integrating the \( \eta^{(k)} \) term \( k \) times.
Many of these terms will vanish due to the boundary conditions we specified for \( \eta \).
This then gives
\[
	F[y+\varepsilon \eta] - F[y] = \varepsilon\int_\alpha^\beta \qty(\pdv{f}{y} \eta - \dv{x} \pdv{f}{y'}\eta + \dots + (-1)^n \dv[n]{x} \pdv{f}{y^{(n)}}\eta) \dd{x} + O(\varepsilon^2)
\]
Applying the fundamental lemma of calculus of variations, we have
\[
	\pdv{f}{y} - \dv{x} \pdv{f}{y'} + \dots + (-1)^n \dv[n]{x} \pdv{f}{y^{(n)}} = 0
\]
This is the Euler--Lagrange equation in the context of a function with higher derivatives.
The alternating signs come from the negative signs produced in the iterated integration by parts.

\subsection{First integral for \( n = 2 \)}
Suppose \( n = 2 \).
If \(\pdv{f}{y} = 0\), we have
\[
	\dv{x}\pdv{f}{y'} - \dv[2]{x}\pdv{f}{y''} = 0
\]
Hence
\[
	\pdv{f}{y'} - \dv{x}\pdv{f}{y''} = \text{constant}
\]

\begin{example}
	Extremise the functional
	\[
		F[y] = \int_0^1 (y'')^2 \dd{x}
	\]
	subject to the conditions
	\[
		y(0) = y'(0) = 0;\quad y(1) = 0;\quad y'(1) = 1
	\]
	Using the above first integral form, we have
	\[
		\dv{x}(2y'') = \text{constant} \implies y''' = k
	\]
	for some \( k \in \mathbb R \).
	Imposing the boundary conditions on this cubic gives
	\[
		y = x^3 - x^2
	\]
	Now, we are going to show that this is an absolute \textit{minimum} of the functional, not just a stationary point.
	Let \( y_0 = x^2 - x^2 \).
	Consider a variation \( \eta \) of \( y_0 \), where all relevant endpoints of \( \eta \) are zero.
	In this case, we are \textit{not} going to assume that \( \eta \) is small; we will simply look at all possible variations.
	\[
		F[y_0 + \eta] - F[y_0] = \underbrace{\int_0^1 (\eta'')^2 \dd{x}}_{> 0} + 2\int_0^1 y_0'' \eta'' \dd{x}
	\]
	Substituting for \( y_0 \), given that \( \eta \not\equiv 0 \),
	\begin{align*}
		F[y_0 + \eta] - F[y_0] & > 4 \int_0^1 (3x-1)\eta'' \dd{x}                                    \\
		                       & = 4\qty{[-\eta']_0^1 + \int_0^1\qty[\dv{x}(3x\eta') - \eta']\dd{x}} \\
		                       & = 4\qty{\int_0^1\qty[\dv{x}(3x\eta') - \eta']\dd{x}}                \\
		                       & = 4\qty{\qty[3x\eta']_0^1 - [3\eta]_0^1}                            \\
		                       & = 0
	\end{align*}
	Hence \( y_0 \) is an absolute minimum of \( F \).
	This method of showing \( y_0 \) is an absolute minimum is easier than calculating second variations, where we know the solution \( y_0 \).
\end{example}

\subsection{Principle of least action}
Consider a particle moving in \( \mathbb R^3 \) with kinetic energy \( T \) and potential energy \( V \).
We define the \textit{Lagrangian} to be
\[
	L(\vb x, \dot {\vb x}, t) = T - V
\]
We now define the \textit{action} to be
\[
	S[\vb x] = \int_{t_1}^{t_2} L \dd{t}
\]
We can now formulate the principle of least (or stationary) action: on the path of motion of a particle,
\[
	\fdv{S}{\vb x} = 0
\]
Equivalently, \( L \) satisfies the Euler--Lagrange equations:
\[
	\pdv{L}{x_i} - \dv{t}\pdv{L}{\dot x_i} = 0
\]
Consider
\[
	T = \frac{1}{2}m\abs{\dot{\vb x}}^2;\quad V = V(\vb x)
\]
The Euler--Lagrange equations are now
\begin{align*}
	\dv{t}\pdv{L}{\dot x_i} & = \pdv{L}{x_i}  \\
	m \ddot x_i             & = -\pdv{V}{x_i} \\
	\implies m \ddot{\vb x} & = -\grad V
\end{align*}
This is exactly Newton's second law, derived from the principle of stationary action.

\subsection{Central forces}
\begin{example}
	Consider a central force in the plane.
	The Lagrangian is
	\[
		L = T - V = \frac{1}{2}m\qty(\dot r^2 + r^2 \dot \theta^2) - V(r)
	\]
	The Euler--Lagrange equation gives
	\begin{align*}
		\dv{t}\pdv{L}{\dot r} - \pdv{L}{r}           & = 0 \\
		\dv{t}\pdv{L}{\dot \theta} - \pdv{L}{\theta} & = 0
	\end{align*}
	Since \( \pdv{L}{\theta} = 0 \), we have a first integral form:
	\[
		\pdv{L}{\dot \theta} = mr^2 \dot \theta = \text{constant}
	\]
	This can be interpreted physically as the law of conservation of angular momentum.
	Further, we have \( \pdv{L}{t} = 0 \) so we have another first integral:
	\begin{align*}
		\dot r \pdv{L}{\dot r} + \dot\theta \pdv{L}{\dot\theta} - L                              & = \text{constant} \\
		m\dot r^2 + mr^2\dot\theta^2 - \frac{1}{2}m\dot r^2 - \frac{1}{2}mr^2\dot\theta^2 + V(r) & = \text{constant} \\
		\frac{1}{2} m \qty( \dot r^2 + r^2\dot\theta^2 ) + V(r)                                  & = \text{constant}
	\end{align*}
	The left hand side is the total energy of the system, denoted \( E \).
	This is the law of conservation of energy.
\end{example}

\subsection{Configuration space and generalised coordinates}
\begin{example}
	Consider \( N \) particles moving in \( \mathbb R^3 \).
	Typically we represent each point as a distinct vector in \( \mathbb R^3 \) that changes over time.
	We can alternatively consider a point in \( \mathbb R^{3N} \), which contains the information about every point.
	This is called the configuration space.
	The Lagrangian in configuration space is
	\[
		L = L(q_i, \dot {q_i}, t)
	\]
	where \( \vb q \) is the combined position vector of all \( N \) points, and likewise \( \dot{\vb q} \) is the combined velocity.
\end{example}
