\subsection{Dirac delta function}
\begin{definition}
	We define a generalised function \( \delta(x - \xi) \) such that
	\begin{enumerate}[(i)]
		\item \( \delta(x-\xi) = 0 \) for all \( x \neq \xi \);
		\item \( \int_{-\infty}^\infty \delta(x-\xi) \dd{x} = 1 \).
	\end{enumerate}
	This acts as a linear operator \( \int \dd{x} \delta(x - \xi) \) on some function \( f(x) \) to produce a number \( f(\xi) \).
	\[
		\int_{-\infty}^\infty \dd{x} \delta(x-\xi) f(x) = f(\xi)
	\]
	This relationship holds provided that \( f(x) \) is sufficiently `well-behaved' at \( x=\xi \) and \( x\to\pm \infty \).
\end{definition}
\begin{remark}
	Strictly, the \( \delta \) `function' is classified as a distribution, not as a function.
	For this reason, we will never use \( \delta \) outside an integral, although such an integral may be implied.
	The \( \delta \) function represnts a unit point source or impulse.
\end{remark}
We can approximate the \( \delta \) function using a Gaussian approximation.
\[
	\delta_\varepsilon(x) = \frac{1}{\varepsilon \sqrt{\pi}} \exp[-\frac{x^2}{\varepsilon^2}]
\]
Therefore,
\begin{align*}
	\int_{-\infty}^\infty f(x) \delta(x) \dd{x} & = \lim_{\varepsilon \to 0} \int_{-\infty}^\infty \frac{1}{\varepsilon \sqrt{\pi}} \exp[-\frac{x^2}{\varepsilon^2}] f(x) \dd{x}            \\
	                                            & = \lim_{\varepsilon \to 0} \int_{-\infty}^\infty \frac{1}{\varepsilon \sqrt{\pi}} \exp[-y^2] f(\varepsilon y) \dd{y}                      \\
	                                            & = \lim_{\varepsilon \to 0} \int_{-\infty}^\infty \frac{1}{\varepsilon \sqrt{\pi}} \exp[-y^2] [f(0) + \varepsilon y f'(0) + \cdots] \dd{y} \\
	                                            & = f(0)
\end{align*}
for all well-behaved functions \( f \) at \( 0, \pm \infty \).
We could alternatively use the Dirichlet kernel
\[
	\delta_n(x) = \frac{\sin n x}{\pi x} = \frac{1}{2\pi} \int_{-n}^n e^{ikx} \dd{k}
\]
or even
\[
	\delta_n(x) = \frac{n}{2} \sech^2 nx
\]

\subsection{Integral and derivative of delta function}
We define the Heaviside step function by
\[
	H(x) = \begin{cases}
		1 & x \geq 0 \\
		0 & x < 0
	\end{cases}
\]
For \( x \neq 0 \), we have
\[
	H(x) = \int_{-\infty}^x \delta(t) \dd{t}
\]
Thus,
\[
	\dv{x} H(x) = \delta(x)
\]
where this identification takes place under an implied integral.
We define \( \delta'(x) \) using integration by parts.
\begin{align*}
	\int_{-\infty}^\infty \delta'(x-\xi) f(x) \dd{x} & = \qty[\delta(x-\xi) f(x)]_{-\infty}^\infty - \int_{-\infty}^\infty \delta(x-\xi) f'(x) \dd{x} \\
	                                                 & = - \int_{-\infty}^\infty \delta(x-\xi) f'(x) \dd{x}                                           \\
	                                                 & = - f'(\xi)
\end{align*}
This is valid for all \( f \) that are smooth at \( x = \xi \).
\begin{example}
	Consider the Gaussian approximation:
	\[
		\delta_\varepsilon(x) = \frac{1}{\varepsilon \sqrt{\pi}} \exp[-\frac{x^2}{\varepsilon^2}]
	\]
	Then,
	\[
		\delta_\varepsilon'(x) = \frac{-2x}{\varepsilon^3 \sqrt{\pi}} \exp[-\frac{x^2}{\varepsilon^2}]
	\]
\end{example}

\subsection{Properties of delta function}
Note that
\[
	\int_a^b f(x) \delta(x-\xi) \dd{x} = \begin{cases}
		f(\xi) & a < \xi < b      \\
		0      & \text{otherwise}
	\end{cases}
\]
So the \( \delta \) function only `samples' values within the integral range.
This is known as the sampling property.
Let \( u = -(x-\xi) \), and consider
\begin{align*}
	\int_{-\infty}^\infty f(x) \delta\qty(-(x-\xi)) \dd{x} & = \int_{\infty}^{-\infty} f(\xi - u) \delta(u) (-\dd{u}) \\
	                                                       & = \int_{-\infty}^\infty f(\xi - u) \delta(u) \dd{u}      \\
	                                                       & = f(\xi)
\end{align*}
Hence,
\[
	\int_{-\infty}^\infty f(x) \delta\qty(-(x-\xi)) \dd{x} = \int_{-\infty}^\infty f(x) \delta(x-\xi) \dd{x}
\]
This is called the even property.
Now, consider
\[
	\int_{-\infty}^\infty f(x) \delta(a(x-\xi)) \dd{x} = \frac{1}{\abs{a}}f(\xi)
\]
This is the scaling property.
Let \( g(x) \) be a function with \( n \) isolated roots at \( x_1, \dots, x_n \).
Then, assuming \( g'(x) \) does not vanish at the \( x_i \),
\[
	\delta(g(x)) = \sum_{i=1}^n \frac{\delta(x - x_i)}{\abs{g'(x_i)}}
\]
This is a generalisation of the above, known as the advanced scaling property.
Now, if \( g(x) \) is continuous at \( x = 0 \), then \( g(x) \delta(x) \) equivalent to \( g(0) \delta(x) \) inside an integral.
This is known as the isolation property.

\subsection{Fourier series expansion of delta function}
Consider a complex Fourier series expansion,
\[
	\delta(x) = \sum_{n=-\infty}^\infty c_n e^{in\pi x/L};\quad c_n = \frac{1}{2L}\int_{-L}^L \delta(x) e^{-i n \pi x / L} \dd{x} = \frac{1}{2L}
\]
Hence,
\[
	\delta(x) = \frac{1}{2L} \sum_{n=-\infty}^\infty e^{in\pi x/L}
\]
Let \( f(x) \) be a function, so \( f(x) = \sum_{n=-\infty}^\infty d_n e^{in \pi x / L} \).
Then, their inner product is given by
\[
	\int_{-L}^L f^\star(x) \delta(x) \dd{x} = \frac{1}{2L} \sum_{n = -\infty}^\infty d_n \int_{-L}^L e^{in \pi x/L} e^{in \pi x/L} \dd{x} = \sum_{n = -\infty}^\infty d_n = f(0)
\]
The Fourier expansion of the \( \delta \) function can be extended periodically to the whole real line.
This infinite set of \( \delta \) functions is known as the Dirac comb, given by
\[
	\sum_{m = -\infty}^\infty \delta(x-2mL) = \sum_{n = -\infty}^\infty e^{in \pi x/L}
\]

\subsection{Arbitrary eigenfunction expansion of delta function}
In general, suppose
\[
	\delta(x-\xi) = \sum_{n=1}^\infty a_n y_n(x)
\]
with coefficients
\[
	a_n = \frac{\int_a^b w(x) y_n(x) \delta(x-\xi) \dd{x}}{\int_a^b w(x) y_n(x)^2 \dd{x}} = \frac{w(\xi) y_n(\xi)}{\int_a^b w(x) y_n(x)^2 \dd{x}} = w_n(\xi) Y_n(\xi)
\]
Then,
\[
	\delta(x-\xi) = w(\xi) \sum_{n=1}^\infty Y_n(\xi) Y_n(x) = w(x) \sum_{n=1}^\infty Y_n(\xi) Y_n(x)
\]
since \( \frac{w(x)}{w(\xi)} \delta(x - \xi) = \delta(x - \xi) \).
Hence,
\[
	\delta(x-\xi) = w(x) \sum_{n=1}^\infty \frac{y_n(\xi) y_n(x)}{N_n}
\]
where \( N_n = \int_a^b w y_n^2 \dd{x} \) is a normalisation factor.
\begin{example}
	Consider a Fourier series for \( y(0) = y(1) = 0 \), with \( y_n(x) = \sin n \pi x \).
	From the sine series coefficient expression,
	\[
		\delta(x-\xi) = 2\sum_{n=1}^\infty \sin n \pi \xi \sin n \pi x
	\]
	where \( 0 < \xi < 1 \).
\end{example}

\subsection{Motivation for Green's functions}
Consider a massive static string with tension \( T \) and linear mass density \( \mu \), suspended between fixed ends \( y(0) = y(1) = 0 \).
By resolving forces, we have the time independent form
\[
	T \dv[2]{y}{x} - \mu g = 0
\]
We will solve the inhomogeneous ODE \( - \dv[2]{y}{x} = f(x) \) with \( f(x) = -\frac{\mu g}{T} \).
This has been placed in Sturm-Liouville form.
We can integrate directly and find
\[
	-y = -\frac{\mu g}{2T} x^2 + k_1 x + k_2
\]
Imposing boundary conditions,
\[
	y(x) = \qty(-\frac{\mu g}{T}) \cdot \frac{1}{2}x(1-x)
\]
Consider alternatively a solution obtained by solving the equation for a single point mass \( \delta m = \mu \delta x \) suspended at \( x = \xi \) on an very light string.
We can then superimpose the solutions for each point mass to find the overall solution.
For a single point mass, the solution is given by two straight lines from \( (0,0) \) and \( (1,0) \) to the point mass \( (\xi_i, y_i(\xi_i)) \).
The angles of these straight lines from the horizontal are given by \( \theta_1, \theta_2 \).
Resolving in the \( y \) direction,
\begin{align*}
	0                                           & = T (\sin \theta_1 + \sin \theta_2) - \delta m g                \\
	                                            & = T\qty(\frac{-y_i}{\xi_i} + \frac{-y_i}{1-\xi_i}) - \delta m g \\
	\therefore -T\qty(y_i(1-\xi_i) + y_i \xi_i) & = \delta m g \xi_i(1-\xi_i)                                     \\
	\therefore y_i(\xi_i)                       & = \frac{-\delta m g}{T} \xi_i (1-\xi_i)
\end{align*}
So the solution is
\[
	y_i(x) = \frac{-\delta m g}{T} \begin{cases}
		x(1-\xi_i)    & x < \xi_i \\
		\xi_i (1 - x) & x > \xi_i
	\end{cases}
\]
which is the generalised sawtooth.
This can alternatively be written
\[
	f_i(\xi) G(x,\xi)
\]
where \( f_i \) is a source term, and \( G(x,\xi) \) is the Green's function, the solution for a unit point source.
Since the differential equation is linear, we can sum the solutions, giving
\[
	y(x) = \sum_{i=1}^N f_i(\xi) G(x, \xi_i)
\]
Taking a continuum limit,
\[
	f_i(\xi) = \frac{-\delta m g}{T} = \frac{-\mu \delta x g}{T} \equiv f(x) \dd{x} \implies f(x) = \frac{-\mu g}{T}
\]
which gives
\[
	y(x) = \int_0^1 f(\xi) G(x,\xi) \dd{\xi}
\]
Substituting the Green's function,
\begin{align*}
	y(x) & = \qty(\frac{-\mu g}{T}) \qty[ \int_0^x \xi(1-x) \dd{\xi} + \int_x^1 x(1-\xi) \dd{\xi}]              \\
	     & = \qty(\frac{-\mu g}{T}) \qty{ \qty[\frac{\xi^2}{2}(1-x)]_0^x + \qty[x(\xi - \frac{\xi^2}{2})]_x^1 } \\
	     & = \qty(\frac{-\mu g}{T}) \qty(\frac{x^2}{2}(1-x) - 0 + \frac{x}{2} - x\qty(x-\frac{x^2}{2}))         \\
	     & = \qty(\frac{-\mu g}{T}) \cdot \frac{1}{2}x(1-x)
\end{align*}
So we have found the correct solution in two ways; once by direct integration, and once by superimposing point solutions.
In general, direct integration is not trivial, and Green's functions are useful in this case.

\subsection{Definition of Green's function}
We wish to solve the inhomogeneous ODE
\[
	\mathcal L y \equiv \alpha(x) y'' + \beta(x) y' + \gamma(x) y = f(x)
\]
on \( a \leq x \leq b \), where \( \alpha \neq 0 \) and \( \alpha, \beta, \gamma \) are continuous and bounded, taking homogeneous boundary conditions \( y(a) = y(b) = 0 \).
The Green's function for \( \mathcal L \) in this case is defined to be the solution for a unit point source at \( x = \xi \).
That is, \( G(x,\xi) \) is the function that satisfies the boundary conditions and
\[
	\mathcal L G(x,\xi) = \delta(x-\xi)
\]
so \( G(a,\xi) = G(b,\xi) = 0 \).
Then, by linearity, the general solution is given by
\[
	y(x) = \int_a^b f(\xi) G(x,\xi) \dd{\xi}
\]
where \( y(x) \) satisfies the homogeneous boundary conditions.
We can verify this by checking
\[
	\mathcal L y = \int_a^b \mathcal L G(x,\xi) f(\xi) \dd{\xi} = \int_a^b \delta(x-\xi) f(\xi) \dd{\xi} = f(x)
\]
So the solution is given by the inverse operator
\[
	y = \mathcal L^{-1} f;\quad \mathcal L^{-1} = \int_a^b \dd{\xi} G(x,\xi)
\]
The Green's function spits into two parts;
\[
	G(x,\xi) = \begin{cases}
		G_1(x,\xi) & a \leq x < \xi \\
		G_2(x,\xi) & \xi < x < b
	\end{cases}
\]
For all \( x \neq \xi \), we have \( \mathcal L G_1 = \mathcal L G_2 = 0 \), so the parts are homogeneous solutions.
\( G \) satisfies the homogeneous boundary conditions, so \( G_1(a, \xi) = 0 \) and \( G_2(b, \xi) = 0 \).
\( G \) must be continuous at \( x = \xi \), hence \( G_1(\xi, \xi) = G_2(\xi, \xi) \).
There is a jump condition; the derivative of \( G \) is discontinuous at \( x = \xi \).
This satisfies
\[
	[G']_{\xi_-}^{\xi_+} = \eval{\dv{G_2}{x}}_{x = \xi_+} - \eval{\dv{G_1}{x}}_{x = \xi_-} = \frac{1}{\alpha(\xi)}
\]

\subsection{Explicit form for Green's functions}
We want to solve
\[
	\mathcal L G(x,\xi) = \delta(x-\xi)
\]
on \( a \leq x \leq b \), subject to homogeneous boundary conditions \( G(a,\xi) = G(b,\xi) = 0 \).
The functions \( G_1, G_2 \) satisfy the homogeneous equation, so \( \mathcal L G_i(x,\xi) = 0 \).
Suppose there exist two independent homogeneous solutions \( y_1(x), y_2(x) \) to \( \mathcal L y = 0 \).
Then, \( G_1 = A y_1 + B y_2 \), such that \( A y_1(a) + B y_2(a) = 0 \), which gives a constraint between \( A \) and \( B \).
This defines a complementary function \( y_-(x) \) such that \( y_-(a) = 0 \).
The general homogeneous solution with \( G_1(a) = 0 \) is
\[
	G_1 = C y_-
\]
\( C \) will be found later.
Similarly we can define \( y_+ \) as a linear combination of \( y_1, y_2 \) such that \( y_+(b) = 0 \).
\[
	G_2 = D y_+
\]
We require \( G_1(\xi, \xi) = G_2(\xi, \xi) \) for continuity, hence
\[
	C y_-(\xi) = D y_+(\xi)
\]
Since \( [G']_{\xi_-}^{\xi^+} = \frac{1}{\alpha(\xi)} \), we have
\[
	Dy'_+(\xi) - C Y_-'(\xi) = \frac{1}{\alpha(\xi)}
\]
We can solve these equations for \( C, D \) simultaneously to find
\[
	C(\xi) = \frac{y_+(\xi)}{\alpha(\xi)W(\xi)};\quad D(\xi) = \frac{y_-(\xi)}{\alpha(\xi)W(\xi)}
\]
where \( W(\xi) \) is the Wro\'nskian
\[
	W(\xi) = y_-(\xi) y_+'(\xi) - y_+(\xi) y_-'(\xi)
\]
which is nonzero if \( y_-, y_+ \) are linearly independent.
Hence,
\[
	G(x,\xi) = \begin{cases}
		\frac{y_-(x) y_+(\xi)}{\alpha(\xi)W(\xi)} & a \leq x \leq \xi \\
		\frac{y_-(\xi) y_+(x)}{\alpha(\xi)W(\xi)} & \xi \leq x \leq b
	\end{cases}
\]

\subsection{Solving boundary value problems}
We know that the solution of \( \mathcal L y = f \) is
\[
	y(x) = \int_a^b G(x,\xi) f(\xi) \dd{\xi}
\]
We can split this into two intervals given that \( G = G_1 \) for \( \xi > x \) and \( G = G_2 \) for \( \xi < x \).
\begin{align*}
	y(x) & = \int_a^x G_2(x,\xi) f(\xi) \dd{\xi} + \int_x^b G_1(x,\xi) f(\xi) \dd{\xi}                                                               \\
	     & = y_+(x) \int_a^x \frac{y_-(\xi) f(\xi)}{\alpha(\xi)W(\xi)} \dd{\xi} + y_-(x) \int_a^x \frac{y_+(\xi) f(\xi)}{\alpha(\xi)W(\xi)} \dd{\xi}
\end{align*}
Note that if \( \mathcal L \) is in Sturm-Liouville form, so \( \beta = \alpha' \), then the denominator \( \alpha(\xi)W(\xi) \) is a constant.
Further, \( G \) is symmetric; \( G(x,\xi) = G(\xi,x) \).
Often, by convention, we take \( \alpha = 1 \) (however Sturm-Liouville form typically takes \( \alpha < 0 \)).
\begin{example}
	Consider \( y'' - y = f(x) \) with \( y(0) = y(1) = 0 \).
	Homogeneous solutions are \( y_1 = e^x \), \( y_2 = e^{-x} \).
	Imposing boundary conditions,
	\[
		G = \begin{cases}
			C \sinh x    & 0 \leq x < \xi \\
			D \sinh(1-x) & \xi < x \leq b
		\end{cases}
	\]
	Continuity at \( x = \xi \) implies
	\[
		C \sinh \xi = D \sinh (1 - \xi) \implies C = D \frac{\sinh (1-\xi)}{\sinh \xi}
	\]
	The jump condition is
	\[
		-D \cosh(1-\xi) - C \cosh \xi = 1
	\]
	Hence,
	\begin{align*}
		-D\qty[\cosh(1-\xi)\sinh \xi + \sinh(1-\xi)\cosh \xi] & = \sinh \xi                     \\
		-D\qty[\sinh((1-\xi) + \xi)]                          & = \sinh \xi                     \\
		-D\sinh 1                                             & = \sinh \xi                     \\
		D                                                     & = \frac{\sinh \xi}{\sinh 1}     \\
		\therefore C                                          & = \frac{-\sinh(1-\xi)}{\sinh 1}
	\end{align*}
	Therefore,
	\[
		y(x) = \frac{-\sinh(1-x)}{\sinh 1} \int_0^x \sinh \xi f(\xi) \dd{\xi} - \frac{\sinh x}{\sinh 1} \int_x^1 \sinh (1-\xi) f(\xi) \dd{\xi}
	\]
\end{example}
\noindent Suppose we have inhomogeneous boundary conditions.
In this case, we want to find a homogeneous solution \( y_p \) that solves the inhomogeneous boundary conditions.
That is, \( \mathcal L y_p = 0 \) but \( y_p(a), y_p(b) \) are as required for the boundary conditions.
Then, by subtracting this solution from the original equation, we can solve using a homogeneous set of boundary conditions.
For instance, in the above example, suppose \( y(0) = 0, y(1) = 1 \).
We can find a solution \( y_p = \frac{\sinh x}{\sinh 1} \) which has the inhomogeneous boundary conditions but solves the homogeneous problem.

\subsection{Higher-order ODEs}
Suppose \( \mathcal L y = f(x) \) where \( \mathcal L \) is an \( n \)th order linear differential operator, and \( \alpha(x) \) is the coefficient for the highest degree derivative.
Suppose that homogeneous boundary conditions are satisfied.
Then we can define the Green's function in this case to be the function that solves
\[
	\mathcal L G(x,\xi) = \delta(x-\xi)
\]
which has the properties:
\begin{enumerate}[(i)]
	\item \( G_1, G_2 \) are homogeneous solutions satisfying the homogeneous boundary conditions;
	\item \( G_1^{(k)} = G_2^{(k)} \) for \( k \in \qty{0, \dots, n-2} \);
	\item \( G_2^{(n-1)}(\xi^+) - G_1^{(n-1)}(\xi^-) = \frac{1}{\alpha(\xi)} \).
\end{enumerate}

\subsection{Eigenfunction expansions of Green's functions}
Suppose \( \mathcal L \) is in Sturm-Liouville form with eigenfunctions \( y_n(x) \) and eigenvalues \( \lambda_n \).
We seek \( G(x,\xi) = \sum_{n=1}^\infty A_n y_n(x) \) satisfying \( \mathcal L G = \delta(x-\xi) \).
\begin{align*}
	\mathcal L G & = \sum_n A_n \mathcal L y_n        \\
	             & = \sum_n A_n \lambda_n w(x) y_n(x)
\end{align*}
The \( \delta \) function has expansion
\[
	\delta(x-\xi) = w(x) \sum_n \frac{y_n(\xi) y_n(x)}{N_n};\quad N_n = \int w y_n^2 \dd{x}
\]
Hence,
\[
	A_n(\xi) = \frac{y_n(\xi)}{\lambda_n N_n}
\]
Thus,
\[
	G(x,\xi) = \sum_{n=1}^\infty \frac{y_n(\xi) y_n(x)}{\lambda_n \int w y_n^2 \dd{x}} = \sum_{n=1}^\infty \frac{Y_n(\xi) Y_N(x)}{\lambda_n}
\]
which was already obtained earlier in the course when studying Sturm-Liouville theory.

\subsection{Constructing Green's function for an initial value problem}
Suppose we want to solve \( \mathcal L y = f(t) \) for \( t \geq a \) with \( y(a) = y'(a) = 0 \), using \( G(t, \tau) \) satisfying \( \mathcal L g = \delta(t - \tau) \).
For \( t < \tau \), we have
\[
	G_1 = A y_1(t) + B y_2(t);\quad A y_1(a) + B y_2(a) = 0;\quad A y_1'(a) + B y_2'(a) = 0
\]
If \( A \neq B \neq 0 \), then we can solve this by dividing out \( A, B \) and find \( y_1 y_2' - y_2 y_1' = 0 \).
Since the Wro\'nskian at \( a \) cannot be zero, \( A = B = 0 \).
So \( G_1(t,\tau) \equiv 0 \) for \( a \leq t < \tau \), so there is no change until the `impulse' at \( t = \tau \).

For \( t > \tau \), by continuity we must have \( G_2(\tau, \tau) = 0 \).
So we choose a complementary function \( G_2 = D y_+(t) \) with \( y_+(t) = A y_1(t) + B y_2(t) \), and \( y_+(\tau) = 0 \).
The discontinuity in the derivative implies that
\[
	G_2'(\tau, \tau) = Dy_+'(\tau) = \frac{1}{\alpha(\tau)}
\]
Hence,
\[
	A y_1'(\tau) + B y_2'(\tau) = \frac{1}{\alpha(\tau)} \implies D(\tau) = \frac{1}{\alpha(\tau) y_+'(\tau)}
\]
Hence we have a non-trivial solution
\[
	G(t, \tau) = \begin{cases}
		0                                      & t < \tau \\
		\frac{y_+(t)}{\alpha(\tau) y_+'(\tau)} & t > \tau
	\end{cases}
\]
The initial value problem has solution
\[
	y(t) = \int_a^t G_2(t, \tau) f(\tau) \dd{\tau} = \int_a^t \frac{y_+(t) f(\tau)}{y_+'(\tau)} \dd{\tau}
\]
Causality is `built in' to this solution.
Only forces which occur before \( t \) may have an impact on \( y(t) \).
\begin{example}
	Let us solve \( y''-y = f(t) \) with \( y(0) = y'(0) = 0 \).
	The homogeneous solution and initial conditions are
	\[
		t < \tau \implies G_1 \equiv 0
	\]
	and
	\[
		t > \tau \implies G_2 = A e^t + Be^{-t} = D \sinh (t - \tau)
	\]
	Now,
	\[
		[G']_{\tau_-}^{\tau_+} = \frac{1}{\alpha(\tau)} = 1 \implies G'(\tau, \tau) = D \cosh 0 = D = 1
	\]
	Hence, the solution is
	\[
		y(t) = \int_0^t f(\tau) \sinh (t - \tau) \dd{\tau}
	\]
\end{example}
